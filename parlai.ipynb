{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from parlai.scripts.train_model import TrainModel\n",
    "from parlai.agents.hugging_face.gpt2 import Gpt2Agent\n",
    "from transformers import BertTokenizer, GPT2LMHeadModel\n",
    "from parlai.agents.transformer.modules import TransformerGeneratorModel\n",
    "from parlai.core.agents import register_agent\n",
    "from parlai.agents.transformer.generator import GeneratorAgent\n",
    "from parlai.agents.hugging_face.dict import HuggingFaceDictionaryAgent, Gpt2DictionaryAgent\n",
    "from transformers import AutoModel\n",
    "from parlai.core.teachers import register_teacher, DialogTeacher\n",
    "from parlai.scripts.interactive_web import InteractiveWeb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设有两个人（假设分别是A和B）的对话聊天记录\n",
    "# 你可以把这些记录放在一个csv文件(excel也行)。每一行放一问一答\n",
    "# 文件3个字段:text,  label,  start\n",
    "# text: A说的话, 文本数据\n",
    "# label: B对A的回答，文本数据\n",
    "# start: 是否是一次聊天的第一句， True 或者 False \n",
    "# 例子：\n",
    "# text                    label    start\n",
    "# 你好                    你好      True\n",
    "# 你叫什么？               张三      False \n",
    "# 太巧了，我也叫张三        不会吧    False  \n",
    "\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# 设置下parlai怎么读取你的数据\n",
    "@register_teacher(\"my_teacher\")\n",
    "class MyTeacher(DialogTeacher):\n",
    "    def __init__(self, opt, shared=None):\n",
    "    \n",
    "        opt['datafile'] = opt['datatype'].split(':')[0] + \".txt\"\n",
    "        super().__init__(opt, shared)\n",
    "\n",
    "    def setup_data(self, datafile):\n",
    "     \n",
    "        print(f\" ~~ Loading from {datafile} ~~ \")\n",
    "\n",
    "        for _,diag in data.iterrows():\n",
    "            text = diag['txt']\n",
    "            labels = diag['label']\n",
    "            start = diag['start']\n",
    "            if isinstance(text,str) and isinstance(labels,str):\n",
    "                yield (text, labels), start\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 因为使用GPT2-Chinese, 设置下这个模型要使用什么Tokenizer\n",
    "class MyDictionaryAgent(Gpt2DictionaryAgent):\n",
    "\n",
    "    def get_tokenizer(self, opt):\n",
    "        \"\"\" \n",
    "        Instantiate and return the HF tokenizer (e.g. via .from_pretrained())\n",
    "        \"\"\"\n",
    "        return BertTokenizer.from_pretrained(\"uer/gpt2-chinese-cluecorpussmall\")\n",
    "\n",
    "# 告诉Parlai我们使用Gpt-Chinese\n",
    "@register_agent('chinese_gpt2')\n",
    "class ChineseGPT(Gpt2Agent):\n",
    "    ...\n",
    "    @staticmethod\n",
    "    def dictionary_class():\n",
    "        \"\"\"\n",
    "        Return the dictionary class that this agent expects to use.\n",
    "        Can be overridden if a more complex dictionary is required.\n",
    "        \"\"\"\n",
    "        return MyDictionaryAgent\n",
    "\n",
    "# 模型训练啦。要有GPU哈。如果你的数据只有几万条，大概要跑3-6个小时\n",
    "# 如果数据上千万，可能要跑1周的时间\n",
    "TrainModel.main(\n",
    "    model='chinese_gpt2',\n",
    "    model_name='uer/gpt2-chinese-cluecorpussmall',\n",
    "    model_file='./model',\n",
    "    task='my_teacher',\n",
    "    lr=1e-5,\n",
    "    optimizer= 'adam',\n",
    "    warmup_updates=100,\n",
    "    batchsize=8,\n",
    "    fp16=True,\n",
    "    num_epochs =3 , \n",
    "    fp16_impl='mem_efficient'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 模型训练好后，部署在一个web服务器\n",
    "\n",
    "InteractiveWeb.main(\n",
    "    model='chinese_gpt2',\n",
    "    model_file='./model',\n",
    "    inference = 'beam',\n",
    "    beam_size=3,\n",
    "    # beam_min_length =4,\n",
    "    # temperature =0.5,\n",
    "    beam_block_ngram=4,\n",
    "    beam_context_block_ngram=4,\n",
    "    host='0.0.0.0')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e1f392defe650829700f492eb57f9ca780dd56d6bebdcdeef32d1ec2c20a25b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
